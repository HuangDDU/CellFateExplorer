import tempfile
import yaml
import tqdm
import docker

import os
import json
import subprocess

import pandas as pd
import rpy2.robjects as ro

from .._logging import logger
from .fate_backend import Backend, Definition


# DockerBackend: specific implementation of abstract Backend class using Dynverse Docker.
class DynverseDockerBackend(Backend):
    def __init__(self, image_id):
        # logger.debug("DockerBackend __init__")
        self.image_id = image_id
        self.load_backend()

    def load_backend(self):
        """
        ref: pydynverse.wrap.method_create_ti_method_container.create_ti_method_container
        """
        image_id = self.image_id
        # load dynverse docker image
        client = docker.from_env()

        # check docker image exists
        try:
            # exist
            img = client.images.get(image_id)
            logger.debug(f"Docker image({image_id}) loaded")
        except Exception as e:
            # no exist, need pull request
            logger.debug(e)
            logger.info(f"Docker image({image_id}) was not found")
            # client.images.pull(container_id)
            image_name, tag = image_id.split(":")
            self._pull_image_with_progress(image_name, tag=tag, logger_func=logger.info)
            img = client.images.get(image_id)
            logger.info(f"Docker image({image_id}) loaded")

        self._load_definition()  # load definition

    def preprocess(self, inputs, parameters, priors, tmp_wd, seed=0):
        """
        ref: pydynverse/wrap/method_create_ti_method_container._method_execution_preproc_container
        """
        task = inputs
        task["parameters"] = parameters
        task["priors"] = priors
        task["seed"] = seed
        task["verbose"] = True
        write_h5(task, f"{tmp_wd}/input.h5")  # json->h5

    def execute(self, tmp_wd):
        """
        ref: pydynverse/wrap/method_create_ti_method_container._method_execution_execute_container
        """
        args = ["--dataset", "/ti/input.h5", "--output", "/ti/output.h5"]

        client = docker.from_env()
        container = client.containers.run(
            image=self.definition["run"]["image_id"],
            command=args,  # r R script command args in Docker
            volumes=[f"{tmp_wd}:/ti"],
            working_dir="/ti/workspace",
            detach=True,
        )

        log_list = [log.decode("utf-8").strip() for log in container.logs(stream=True)]
        container.wait()  # wait until docker finish
        container.stop()
        container.remove()

        log = "\n".join(log_list)
        output_h5_filename = f"{tmp_wd}/output.h5"
        if not os.path.exists(output_h5_filename):
            # no h5 file generated by docker, show error log
            logger.error("Docker Error!!!")
            logger.error(log)
        else:
            logger.debug("Docker Finish")
            logger.debug(log)
            dynverse_docker_output = read_h5(f"{tmp_wd}/output.h5")  # read docker result h5
            return dynverse_docker_output

    def postprocess(self, fadata, trajectory):
        fadata.add_trajectory(
            milestone_network=trajectory.milestone_network,
            divergence_regions=trajectory.divergence_regions,
            milestone_percentages=trajectory.milestone_percentages,
        )

    def run(self, fadata, parameters):

        inputs = self._extract_inputs(fadata, self.definition.get_inputs_df())  # extract main input
        priors = self._extract_priors(fadata, self.definition.get_inputs_df())  # extract prior information
        default_parameters = self.definition.get_parameters()
        if not parameters is None:
            default_parameters.update(parameters)
        parameters = default_parameters

        with tempfile.TemporaryDirectory() as tmp_wd:
            # /tmp/*** temp dir for docker
            logger.debug(f"Temp wd: {tmp_wd}")

            # preprocess
            self.preprocess(inputs, parameters, priors, tmp_wd)

            # method run
            trajectory = self.execute(tmp_wd)

            # postprocess
            self.postprocess(fadata, trajectory)

    def _pull_image_with_progress(self, image_name, tag=None, logger_func=print):
        """
        pull dynverse docker image  and show progress bar with tqdm

        ref: pydynverse.wrap.method_create_ti_method_container.pull_image_with_progress
        """
        if logger_func is None:
            # default logger function is print
            logger_func = print
        client = docker.from_env()
        try:
            logger_func(f"Try to pull image {image_name}:{tag}...\n")
            api_client = docker.APIClient(base_url="unix://var/run/docker.sock")  # stream docker clinet can get log
            pull_logs = api_client.pull(repository=image_name, tag=tag, stream=True, decode=True)  # pull image
            progress_bars = {}  # initialize progress bar, store every layer's progress bar
            for log in pull_logs:
                # pull logs format is JSON, need parse
                if "status" in log:
                    status = log["status"]
                    layer_id = log.get("id", None)
                    progress_detail = log.get("progressDetail", {})
                    current = progress_detail.get("current", 0)  # finished bytes
                    total = progress_detail.get("total", 0)  # total bytes
                    # layer_id and total update progress bar
                    if layer_id and total:
                        if layer_id not in progress_bars:
                            # new propgress bar
                            progress_bars[layer_id] = tqdm(
                                total=total,
                                desc=f"Layer {layer_id[:12]}",
                                unit="B",
                                unit_scale=True,
                                unit_divisor=1024
                            )
                        progress_bars[layer_id].n = current
                        progress_bars[layer_id].refresh()
                    # no progression information, show status
                    elif layer_id:
                        logger_func(f"{status} {layer_id}".strip())
                    else:
                        logger_func(f"{status}".strip())
            # close all progress bars
            for bar in progress_bars.values():
                bar.close()
            logger_func(f"Pull {image_name}:{tag} finish")
        except docker.errors.APIError as e:
            logger_func(f"Pull image failed: {e}")
        except Exception as e:
            logger_func(f"Other Error: {e}")
        finally:
            client.close()

    def _load_definition(self):
        """
        extract and parse definition.yml, including description, required parameters and prior   knowledge 

        ref: pydynverse.wrap.container_get._container_get_definition
        """
        with tempfile.TemporaryDirectory() as tmp_wd:
            # start docker container
            client = docker.from_env()
            container = client.containers.run(
                entrypoint="cp /code/definition.yml /copy_mount/definition.yml",  # aim copy dir
                image=self.image_id,
                volumes=[f"{tmp_wd}:/copy_mount"],
                detach=True,
            )
            container.wait()
            container.stop()
            container.remove()
            # read and parse yml file
            with open(f"{tmp_wd}/definition.yml", 'r') as file:
                definition_raw = yaml.safe_load(file)

        definition = Definition(definition_raw)
        definition["run"] = {"backend": "container", "image_id": self.image_id}
        self.definition = definition


# ====================================================================================================
# ref: pydynverse/util/h5.py
class DynverseDockerInput():
    def __init__(self, expression, expression_id, cell_ids, feature_ids, parameters, priors, seed, verbose):
        self.expression = expression
        self.expression_id = expression_id
        self.cell_ids = cell_ids
        self.feature_ids = feature_ids
        self.parameters = parameters
        self.priors = priors
        self.seed = seed
        self.verbose = verbose

    def save_json(self, input_json_filename):
        self.input_json_filename = input_json_filename
        # 稀疏矩阵不能JSON序列化，需要手动提取行列索引
        expression_dict = {
            "x": self.expression.data.tolist(),
            "i": self.expression.indices.tolist(),
            "p": self.expression.indptr.tolist(),
            "Dim": self.expression.shape,
            # TODO: 表达矩阵行、列名称，暂时这样写，后续再把真实的拉进来
            "rownames": list(self.cell_ids),
            "colnames": list(self.feature_ids)
        }
        input_json = {
            self.expression_id: expression_dict,
            "expression_id": self.expression_id,
            "parameters": self.parameters,
            "priors": self.priors,
            "seed": self.seed,
            "verbose": self.verbose
        }
        # logger.debug(input_json)
        # 对于稀疏矩阵的特殊处理
        with open(input_json_filename, "w") as f:
            json.dump(input_json, f)
        logger.debug(f"Save json successfully, path: {input_json_filename}")

    def json2h5(self, input_h5_filename):
        self.input_h5_filename = input_h5_filename
        # 调用R脚本，把生成的json文件转化为h5文件，作为dynverse docker容器需要的的输入
        Rscript_filename = f"{os.path.dirname(__file__)}/../rscript/docker_input_json2h5.R"
        logger.debug(f"h52json script: {Rscript_filename}")
        command_list = [Rscript_filename, "--input_json_filename",
                        self.input_json_filename, "--input_h5_filename", input_h5_filename]
        result = subprocess.run(command_list, capture_output=True, text=True)
        logger.debug(result)
        if result.returncode == 0:
            logger.debug("json2h5 successful!")
        else:
            logger.debug("json2h5 failed!")

    def __str__(self) -> str:
        return f"{self.expression}"  # 目前查看稀疏矩阵是最直观的输入


class DynverseDockerOutput():
    def __init__(self):
        self.id = None
        self.pseudotime = None

    def h52json(self, output_h5_filename, output_json_filename):

        self.output_h5_filename = output_h5_filename
        self.output_json_filename = output_json_filename
        # 调用R脚本，把dynverse docker的输出的h5文件转化JSON文件
        Rscript_filename = f"{os.path.dirname(__file__)}/../rscript/docker_output_h52json.R"
        logger.debug(f"h52json script: {Rscript_filename}")
        command_list = [Rscript_filename, "--output_h5_filename",
                        output_h5_filename, "--output_json_filename", output_json_filename]
        result = subprocess.run(command_list, capture_output=True, text=True)
        logger.debug(result)
        if result.returncode == 0:
            logger.debug("h52json successful!")
        else:
            logger.debug("h52json failed!")

    def load_json(self):
        # 读取json
        with open(self.output_json_filename, "r") as f:
            output_json = json.load(f)
        logger.debug(
            f"Save json successfully, path: {self.output_json_filename}")
        # 解析JSON
        # 暂时简单设置属性, 后续需要使用数据类型, 再对应转换
        self.id = output_json["id"]
        self.cell_ids = output_json["cell_ids"]
        # 自动提取JSON中的键值对
        for k, v in output_json.items():
            self.__setattr__(k, v)
        # 对共有的部分属性的数据结构修改, 方便后续调用, 这部分其实就是wrapper对于轨迹推断输出结果的封装
        self.milestone_network = pd.DataFrame(self.milestone_network)
        self.milestone_percentages = pd.DataFrame(self.milestone_percentages)
        self.progressions = pd.DataFrame(self.progressions)
        self.divergence_regions = None if (len(self.divergence_regions) == 0) else pd.DataFrame(self.divergence_regions)
        self.dimred = pd.DataFrame(self.dimred, index=self.cell_ids)
        self.dimred_segment_progressions = pd.DataFrame(
            output_json["dimred_segment_progressions"])
        self.dimred_segment_points = pd.DataFrame(
            output_json["dimred_segment_points"])

        # json文件添加，方便查可能不同轨迹推断类型对于wrapper的输出
        self.output_json = output_json

    def __str__(self) -> str:
        return f"""
            id: {self.id}, 
            trajectory_type: {self.trajectory_type}, 
            attribute_list: {self.__dict__.keys()}
            """

    def __getitem__(self, key):
        # 通过键名访问属性
        if hasattr(self, key):
            return getattr(self, key)
        else:
            return None
            # raise KeyError(
            #     f"'{self.__class__.__name__}' object has no attribute '{key}'")

    def get(self, key, default=None):
        return self[key]

    def __setitem__(self, key, value):
        # 通过键名设置属性
        setattr(self, key, value)

    def __contains__(self, item):
        return hasattr(self, item)


def write_h5(x, h5_filename, via_json=True):
    expression_id = x["expression_id"]
    if via_json:
        input_json_filename = f"{h5_filename[:-3]}.json"  # 中间json文件
        input_h5_filename = h5_filename
        dynverse_docker_input = DynverseDockerInput(
            expression=x[expression_id],  # 从AnnData里提取
            expression_id=expression_id,
            cell_ids=x["cell_ids"],
            feature_ids=x["feature_ids"],
            parameters=x["parameters"],
            priors=x["priors"],
            seed=x["seed"],
            verbose=x["verbose"]
        )
        dynverse_docker_input.save_json(input_json_filename)
        dynverse_docker_input.json2h5(input_h5_filename)
    else:
        # TODO: 直接通过装饰器的自动转换，不使用json交换文件和单独的R脚本
        task = x
        task[expression_id] = None
        ro.globalenv["task"] = ro.ListVector(task)  # 待添加的内容转换到R变量里
        ro.globalenv["h5_filename"] = ro.ListVector(h5_filename)  # 待添加的内容转换到R变量里
        ro.r("dynutils::write_h5(task, file.path(paths$dir_dynwrap, h5_filename))")  # 调用R修改


def read_h5(h5_filename, via_json=True):
    if via_json:
        output_h5_filename = h5_filename
        output_json_filename = f"{h5_filename[:-3]}.json"  # 中间json文件
        dynverse_docker_output = DynverseDockerOutput()
        dynverse_docker_output.h52json(output_h5_filename, output_json_filename)
        dynverse_docker_output.load_json()
        return dynverse_docker_output
    else:
        # TODO: 直接通过装饰器的自动转换，不使用json交换文件和单独的R脚本
        return
