import os
import tempfile
import json
import pickle
import docker

from .._logging import logger
from .fate_backend import DockerBackend


# CfeDockerBackend: specific implementation of abstract Backend class using CFE Docker..
class CFEDockerBackend(DockerBackend):
    def __init__(self, image_id):
        logger.debug("CFEDockerBackend __init__")

        self.image_id = image_id
        self.load_backend()  # implemented in DockerBackend

    def preprocess(self, fadata, prior_information, parameters, tmp_wd):
        # save adata h5ad , prior information and parameters json file in tmp_wd dir
        fadata.write_h5ad(f"{tmp_wd}/adata.h5ad")

        with open(f"{tmp_wd}/prior_information.json", "w") as f:
            json.dump(prior_information, f)

        with open(f"{tmp_wd}/parameters.json", "w") as f:
            json.dump(parameters, f)

    def execute(self, tmp_wd):
        # CFE Docker run, save dict.pkl in tmp_wd dir, return trajectory_dict
        tmp_wd
        trajectory_dict = {}

        client = docker.from_env()
        container = client.containers.run(
            image=self.definition["run"]["image_id"],
            command="python run.py",
            volumes=[f"{tmp_wd}:/data"],
            working_dir="/code",
            detach=True,
        )  # all are saved in "/data" dir and sync to master

        log_list = [log.decode("utf-8").strip() for log in container.logs(stream=True)]
        container.wait()  # wait until docker finish
        container.stop()
        container.remove()

        log = "\n".join(log_list)
        output_pkl_filename = f"{tmp_wd}/output.pkl"
        if not os.path.exists(output_pkl_filename):
            # no h5 file generated by docker, show error log
            logger.error("Docker Error!!!")
            logger.error(log)
        else:
            logger.debug("Docker Finish")
            logger.debug(log)
            with open(f"{tmp_wd}/output.pkl", "rb") as f:
                trajectory_dict = pickle.load(f)
            return trajectory_dict

    def postprocess(self, fadata, trajectory_dict):
        # save trajectory_dict
        fadata.add_trajectory_by_type(trajectory_dict)

    def run(self, fadata, parameters):
        # TODO:
        prior_information = self._extract_prior_information(fadata, self.definition.get_inputs_df())  # check prior information and add to fadata
        default_parameters = self.definition.get_parameters()
        if parameters is not None:
            default_parameters.update(parameters)
        parameters = default_parameters

        with tempfile.TemporaryDirectory() as tmp_wd:
            logger.debug(f"Temp wd: {tmp_wd}")
            self.preprocess(fadata, prior_information, parameters, tmp_wd)

            trajectory_dict = self.execute(tmp_wd)

            self.postprocess(fadata, trajectory_dict)
